{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p align=\"center\" style=\"color:rgb(55, 113, 197);\">[16-825: Learning for 3D Vision](https://learning3d.github.io/)</p>\n",
    "### <p align=\"center\" style=\"color:rgb(0, 0, 0);\">Project 4</p>\n",
    "<p align=\"center\" style=\"color:rgb(55, 113, 197);\">\n",
    "    Shreyas Jha &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "    <a href=\"https://github.com/Shreyas120/l3d_assignment4\">Code</a> \n",
    "</p>\n",
    "\n",
    "<!-- Color theme\n",
    "    Dark color:rgb(42, 88, 153)\n",
    "    Medium (55, 113, 197)\n",
    "    Light and bright color:rgb(68, 129, 211)\n",
    " -->\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <p align=\"center\" style=\"color:rgb(55, 113, 197);\">1.&nbsp;3D Gaussian Splatting </p>\n",
    "\n",
    "### <p align=\"center\" style=\"color:rgb(55, 113, 197);\">1.1.5 Rendering</p>\n",
    "\n",
    "#### <p align=\"center\" style=\"color:rgb(42, 88, 153);\">![Render 1.1.5](./Q1/output/q1_render.gif)</p>\n",
    "\n",
    "\n",
    "### <p align=\"center\" style=\"color:rgb(55, 113, 197);\">1.2 Training</p>\n",
    "\n",
    "#### <p align=\"center\" style=\"color:rgb(42, 88, 153);\">![GIF 1](./Q1/output/q1_training_progress.gif)</p>\n",
    "\n",
    "#### <p align=\"center\" style=\"color:rgb(42, 88, 153);\">![GIF 2](./Q1/output/q1_training_final_renders.gif)</p>\n",
    "\n",
    "Learning rates for each parameter\n",
    "\n",
    "\n",
    "\n",
    "|Param|Learning rate|\n",
    "|-----|-----|\n",
    "|gaussians.pre_act_opacities|0.005|\n",
    "|gaussians.pre_act_scales|0.005|\n",
    "|gaussians.colours|0.005|\n",
    "|gaussians.means|0.001|\n",
    "\n",
    "                \n",
    "Number of iterations = 1000\n",
    "\n",
    "PSNR and SSIM\n",
    "\n",
    "\n",
    "### <p align=\"center\" style=\"color:rgb(55, 113, 197);\">1.3.1 Rendering Using Spherical Harmonics</p>\n",
    "\n",
    "#### <p align=\"center\" style=\"color:rgb(42, 88, 153);\">![Render 1.1.5](./Q1/output/q1_render.gif)</p>\n",
    "\n",
    "#### <p align=\"center\" style=\"color:rgb(42, 88, 153);\">![Render SPH](./Q1/output/q1_render_sph.gif)</p>\n",
    "\n",
    "2 side by side RGB image comparisons of the renderings obtained from both the case (from same view/frame)\n",
    "\n",
    "|Frame|DC Harmonics|Spherical Harmonics|Comment| \n",
    "|-|-|-|-| \n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <p align=\"center\" style=\"color:rgb(55, 113, 197);\">2.&nbsp;Diffusion-guided Optimization </p>\n",
    "\n",
    "### <p align=\"center\" style=\"color:rgb(55, 113, 197);\">2.1.&nbsp;SDS Loss + Image Optimization  </p>\n",
    "\n",
    "\n",
    "| Prompt | Without guidance| With guidance|\n",
    "|---------------------------|-----------------|--------------|\n",
    "|a hamburger                | ![](./Q2/output/image/a_hamburgerguide_0/output_a_iter_700.png) 700 Iterations |  ![](./Q2/output/image/a_hamburgerguide_1/output.png) 2000 Iterations|      \n",
    "|a standing corgi dog       | ![](./Q2/output/image/a_standing_corgi_dogguide_0/output_a_iter_1500.png) 1500 Iterations |  ![](./Q2/output/image/a_standing_corgi_dogguide_1/output.png) 2000 Iterations|      \n",
    "|a wine glass with green tea| ![](./Q2/output/image/a_wine_glass_with_green_teaguide_0/output_a_iter_1400.png) 1400 Iterations |  ![](./Q2/output/image/a_wine_glass_with_green_teaguide_1/output.png) 2000 Iterations|      \n",
    "|a work desk with a view    | ![](./Q2/output/image/a_work_desk_with_a_viewguide_0/output_a_iter_1500.png) 1500 Iterations |  ![](./Q2/output/image/a_work_desk_with_a_viewguide_1/output.png) 2000 Iterations|      \n",
    "\n",
    "(Without guidance results are shown at best iteration / 2000 iterations)\n",
    "\n",
    "### <p align=\"center\" style=\"color:rgb(55, 113, 197);\">2.2.&nbsp;Texture Map Optimization for Mesh </p>\n",
    "\n",
    "Prompt 1: \"black skin with neon spots\"\n",
    "#### <p align=\"center\" style=\"color:rgb(42, 88, 153);\">![Textured Mesh 1](./Q2/output/mesh/black_skin_with_neon_spots/final_mesh.gif)</p>\n",
    "\n",
    "\n",
    "Prompt 2: \"neon zebra\" \n",
    "#### <p align=\"center\" style=\"color:rgb(42, 88, 153);\">![Textured Mesh 2](./Q2/output/mesh/neon_zebra/final_mesh.gif)</p>\n",
    "\n",
    "\n",
    "### <p align=\"center\" style=\"color:rgb(55, 113, 197);\">2.3.&nbsp;NeRF Optimization </p>\n",
    "\n",
    "Prompt 1: \"a standing corgi dog\"\n",
    "#### <p align=\"center\" style=\"color:rgb(42, 88, 153);\">![mp4 1](./)</p>\n",
    "\n",
    "Prompt 2: \"a yellow bear\"\n",
    "#### <p align=\"center\" style=\"color:rgb(42, 88, 153);\">![mp4 2](./)</p>\n",
    "\n",
    "\n",
    "Prompt 3: \"sunglass with glare\" \n",
    "#### <p align=\"center\" style=\"color:rgb(42, 88, 153);\">![mp4 3](./)</p>\n",
    "\n",
    "\n",
    "### <p align=\"center\" style=\"color:rgb(55, 113, 197);\">2.4.1.&nbsp;View-dependent text embedding  </p>\n",
    "\n",
    "Prompt 1: \"a standing corgi dog\"\n",
    "#### <p align=\"center\" style=\"color:rgb(42, 88, 153);\">![mp4 1](./)</p>\n",
    "\n",
    "Prompt 2: \"knight in a shining armour\"\n",
    "#### <p align=\"center\" style=\"color:rgb(42, 88, 153);\">![mp4 2](./)</p>\n",
    "\n",
    "\n",
    "Compare the visual results with what you obtain in Q2.3 and qualitatively analyse the effects of view-dependent text conditioning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\" style=\"color:rgb(55, 113, 197);\">Late days used</p>\n",
    "\n",
    "<p align=\"center\" style=\"color:rgb(42, 88, 153);\">![Two](./images/two.png)</p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
